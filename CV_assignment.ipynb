{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> CV Assignment </h3>\n",
    "<h4> In this project, I've implemented a binary classifier and a bidirectional LSTM network. The dataset used consists of various tweets.</h4> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packages rerquired for data preprocessing and representation\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "# packages required for building the model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential \n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers.embeddings import Embedding \n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing import sequence\n",
    "# package required for computation of metrics\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix, accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               Text\n",
       "0     1  Today, Senate Dems vote to #SaveTheInternet. P...\n",
       "1     1  RT @WinterHavenSun: Winter Haven resident / Al...\n",
       "2     1  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...\n",
       "3     1  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...\n",
       "4     1  RT @Vegalteno: Hurricane season starts on June..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the given dataset\n",
    "df = pd.read_csv('CVAssignmentDataset.csv')\n",
    "df.dropna(axis = 0, inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>The following code blocks contain codes which are used for Exploratory Data Analysis<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86460, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 86460 entries, 0 to 86460\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Class   86460 non-null  object\n",
      " 1   Text    86460 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(close=None, block=None)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Class', data = df)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    44392\n",
       "1    42068\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "length = df['Text'].str.len()\n",
    "plt.hist(length, bins=20, label=\"none\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Conclusions</h3>\n",
    "<br>\n",
    "Total number of rows = 86460 <br>\n",
    "Number of values under class 0 : 44392 <br>\n",
    "Number of values under class 1 : 42068\n",
    "\n",
    "<h3>The data preprocessing phase begins now</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting entries under 'Text' to string type\n",
    "df['Text']=df['Text'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function used to remove unwanted text patterns\n",
    "def remove_pattern(input_text, pattern):\n",
    "    r = re.findall(pattern, input_text)\n",
    "    for i in r:\n",
    "        input_text = re.sub(i, '', input_text)\n",
    "    return input_text\n",
    "df['processed_tweet'] = np.vectorize(remove_pattern)(df['Text'], \"@[\\w]*\") #removing special characters(except #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-1b3ca29d3fbe>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['processed_tweet'] = df['processed_tweet'].str.replace(\"[^a-zA-Z#]\", \" \") #removing everything except alphabets and #\n",
      "<ipython-input-10-1b3ca29d3fbe>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['processed_tweet'] = df['processed_tweet'].str.replace(r'http\\S+', \" \") #removing links\n"
     ]
    }
   ],
   "source": [
    "df['processed_tweet'] = df['processed_tweet'].str.replace(\"[^a-zA-Z#]\", \" \") #removing everything except alphabets and #\n",
    "df['processed_tweet'] = df['processed_tweet'].str.replace(r'http\\S+', \" \") #removing links\n",
    "# removing words of shorter length\n",
    "df['processed_tweet'] = df['processed_tweet'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kumar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# packages required for further data preprocessing\n",
    "from nltk import word_tokenize, FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Today Senate Dems vote #SaveTheInternet Proud ...\n",
       "1    Winter Haven resident Alta Vista teacher sever...\n",
       "2    noted that Hurricane Maria left approximately ...\n",
       "3    Meeting with Thanks taking time meet with Maru...\n",
       "4    Hurricane season starts June Puerto Rico readi...\n",
       "Name: processed_tweet, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's have a look at the processed data till now\n",
    "df['processed_tweet'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        today senate dems vote # savetheinternet proud...\n",
       "1        winter resident alta vista teacher several rec...\n",
       "2        noted hurricane maria left approximately billi...\n",
       "3        meeting thanks taking time meet marucci guzman...\n",
       "4        hurricane season start june puerto rico readin...\n",
       "                               ...                        \n",
       "86456    check need executive overreach white house cri...\n",
       "86457    yesterday betty great time learning forestry i...\n",
       "86458    forever grateful service sacrifice major barne...\n",
       "86459                happy first school # cobbbacktoschool\n",
       "86460    # zika fear realized florida house acted preve...\n",
       "Name: processed_tweet, Length: 86460, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting the processed_tweet column in  pandas to a numpy array\n",
    "dataArray = df.processed_tweet.to_numpy()\n",
    "dataList = []\n",
    "lemma = nltk.WordNetLemmatizer()\n",
    "\n",
    "for data in dataArray:\n",
    "    data = data.lower() \n",
    "    data = nltk.word_tokenize(data)\n",
    "    #removal of stop-words(here stopwords.words('english') contains a set of frequently appearing stop words.\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    data = [w for w in data if not w in stop_words]\n",
    "    data = [lemma.lemmatize(word) for word in data] #Lemmatizing(removing inflectional endings and returning the base forms of words)\n",
    "    data = \" \".join(data)\n",
    "    dataList.append(data)\n",
    "\n",
    "\n",
    "dataArray = np.asarray(dataList) #updating dataArray with the obtained list\n",
    "df['processed_tweet'] = dataArray\n",
    "df['processed_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing the processed words using TweetTokenizer\n",
    "from nltk.tokenize.casual import TweetTokenizer\n",
    "tokenizer = TweetTokenizer(reduce_len=True)\n",
    "\n",
    "df['processed_tweet'] = df.processed_tweet.apply(tokenizer.tokenize)\n",
    "\n",
    "# converting the tokens to frequency distribution rankings\n",
    "topWords = 10000 # chosen as given in the problem statement \n",
    "freq_dist = FreqDist(w for t in df.processed_tweet for w in t)\n",
    "tweetTerms = [te for te, cnt in freq_dist.most_common(topWords)]\n",
    "df.processed_tweet = df.processed_tweet.apply(lambda tweet:[tweetTerms.index(te) if te in tweetTerms else 0 for te in tweet])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [1, 121, 851, 55, 0, 2130, 22, 21, 2205, 0, 48...\n",
       "1          [1469, 347, 0, 3600, 199, 705, 964, 33, 199, 0]\n",
       "2        [6084, 544, 1969, 597, 3816, 219, 1035, 12, 7499]\n",
       "3                       [37, 17, 216, 10, 101, 0, 0, 0, 0]\n",
       "4               [544, 694, 257, 1706, 730, 836, 1396, 253]\n",
       "                               ...                        \n",
       "86456           [168, 18, 796, 4302, 282, 5, 6297, 110, 0]\n",
       "86457    [73, 5259, 2, 10, 1039, 6027, 420, 1617, 4966,...\n",
       "86458                      [1458, 326, 45, 490, 495, 0, 0]\n",
       "86459                                   [28, 32, 25, 0, 0]\n",
       "86460    [0, 3114, 1352, 5907, 379, 5, 2766, 484, 212, ...\n",
       "Name: processed_tweet, Length: 86460, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's now have a look at the tokenized and ranked dataset\n",
    "df.processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86460, 50)\n"
     ]
    }
   ],
   "source": [
    "# padding is done to bring the processed dataset to a length of 50, as given in the problem statement\n",
    "x = df.processed_tweet\n",
    "ipLength = 50\n",
    "x = sequence.pad_sequences(x, maxlen = ipLength)\n",
    "print(x.shape)\n",
    "\n",
    "# here the dataset is assigned to a variable x, which will be further used for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [1, 121, 851, 55, 0, 2130, 22, 21, 2205, 0, 48...\n",
       "1          [1469, 347, 0, 3600, 199, 705, 964, 33, 199, 0]\n",
       "2        [6084, 544, 1969, 597, 3816, 219, 1035, 12, 7499]\n",
       "3                       [37, 17, 216, 10, 101, 0, 0, 0, 0]\n",
       "4               [544, 694, 257, 1706, 730, 836, 1396, 253]\n",
       "                               ...                        \n",
       "86456           [168, 18, 796, 4302, 282, 5, 6297, 110, 0]\n",
       "86457    [73, 5259, 2, 10, 1039, 6027, 420, 1617, 4966,...\n",
       "86458                      [1458, 326, 45, 490, 495, 0, 0]\n",
       "86459                                   [28, 32, 25, 0, 0]\n",
       "86460    [0, 3114, 1352, 5907, 379, 5, 2766, 484, 212, ...\n",
       "Name: processed_tweet, Length: 86460, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is how our dataset(with values) looks like, after padding\n",
    "df.processed_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now the labels are assigned to a variable y\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the pre-processed data into training and testing datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the splitted data into arrays\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(y_train)\n",
    "x_test = np.asarray(x_test)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "# type conversion to float\n",
    "x_train = x_train.astype(float)\n",
    "y_train = y_train.astype(float)\n",
    "x_test = x_test.astype(float)\n",
    "y_test = y_test.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the model as given in the model architecture image in the problem statement\n",
    "def baseline_model():\n",
    "    \n",
    "    model = Sequential() # one input tensor and one output tensor\n",
    "    embeddingVectorLength = 32 # assigned as given in the image\n",
    "    \n",
    "    model.add(layers.Input(shape = ipLength, dtype='float64')) # first layer(input)\n",
    "    model.add(Embedding(topWords, embeddingVectorLength, input_length = ipLength))\n",
    "    \n",
    "    model.add(Conv1D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu')) #kernel size is chosen as 3 pertaining to normal convention\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Bidirectional(LSTM(256)))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 50, 32)            320000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 50, 32)            3104      \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 25, 32)            0         \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 25, 512)           591872    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 25, 512)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 512)               1574912   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,540,513\n",
      "Trainable params: 3,540,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/3\n",
      "679/679 [==============================] - 242s 349ms/step - loss: 0.6338 - accuracy: 0.6048 - val_loss: 0.5163 - val_accuracy: 0.7296\n",
      "Epoch 2/3\n",
      "679/679 [==============================] - 255s 375ms/step - loss: 0.4320 - accuracy: 0.7949 - val_loss: 0.5393 - val_accuracy: 0.7308\n",
      "Epoch 3/3\n",
      "679/679 [==============================] - 253s 372ms/step - loss: 0.3098 - accuracy: 0.8619 - val_loss: 0.6025 - val_accuracy: 0.7355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1bc1e962d90>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's run the summary of the model, and start training\n",
    "model = baseline_model()\n",
    "print(model.summary())\n",
    "model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.33, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<p> After multiple trials, the number of epochs is chosen to be 3 and validation_split is assigned a value of 0.33(pertaining to standard convention). After observing the increase in accuracy and reduction in loss, it is inferred that the model works fine. It is also noted that the validation loss increases, over the epochs. It was observed that for more number of epochs, the validation loss fluctuates (i.e) reduces and later increases which is an indication of overfitting. This is a common phenomenon, observed in many models. Hence to avoid that, the number of epochs is reduced to 3 and the test_size is also reduced. This leads to increased accuracy of predicted values and lesser chances of overfitting </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7313439740920656\n",
      "Confusion Matrix [[8525 2507]\n",
      " [3300 7283]]\n",
      "Matthews Correlation Coefficient 0.46288772322516836\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test, use_multiprocessing=True)\n",
    "print('Accuracy {}'.format(accuracy_score(y_test, np.round(y_pred))))\n",
    "print('Confusion Matrix {}'.format(confusion_matrix(y_test, np.round(y_pred))))\n",
    "print('Matthews Correlation Coefficient {}'.format(matthews_corrcoef(y_test, np.round(y_pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score 0.7149658862219603\n"
     ]
    }
   ],
   "source": [
    "print('F1 score {}'.format(f1_score(y_test, np.round(y_pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By observing the results of the metrics, we infer that the model is now predicting values with an accuracy of 0.7313 and with an MCC value of 0.4628. By looking at the Confusion Matrix, the combined values of FP and FN is lesser than that of TP and TN, which indicates that the model predicts majority of the values correctly. Also the F1 score turns out to be 0.7149, which is also an indication of fine working of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
